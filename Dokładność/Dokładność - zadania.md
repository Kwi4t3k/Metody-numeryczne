## Zadanie 1
SprawdÅº, czy suma dwÃ³ch liczb zmiennoprzecinkowych (zarÃ³wno w pojedynczej jak i podwÃ³jnej precyzji) jest zawsze rÃ³wna oczekiwanej matematycznie wartoÅ›ci. WyjaÅ›nij, dlaczego odpowiedÅº moÅ¼e byÄ‡ bÅ‚Ä™dna przy bezpoÅ›rednim porÃ³wnaniu liczb zmiennoprzecinkowych.

```python
import numpy as np  
  
def suma_pojedyncza_precyzja(a, b):  
    a32 = np.float32(a)  
    b32 = np.float32(b)  
    return np.float32(a32 + b32)  
  
poj = suma_pojedyncza_precyzja(0.1, 0.2)  
  
print(poj)  
  
def suma_podwojna_precyzja(a: float, b: float) -> float:  
    return a + b  
  
pod = suma_podwojna_precyzja(0.1, 0.2)  
  
print(pod)  
  
print("Czy rÃ³wne?: ", poj == pod)
```

```
0.3
0.30000000000000004
Czy rÃ³wne?:  False
```

### dlaczego odpowiedÅº moÅ¼e byÄ‡ bÅ‚Ä™dna przy bezpoÅ›rednim porÃ³wnaniu liczb zmiennoprzecinkowych

Komputery przechowujÄ… liczby zmiennoprzecinkowe w formacie binarnym (standard IEEE 754).

NiektÃ³re liczby dziesiÄ™tne, takie jak:

- 0.1
    
- 0.2
    
- 0.3
    

**nie majÄ… dokÅ‚adnej reprezentacji w systemie binarnym**, podobnie jak 1/3 nie ma skoÅ„czonego zapisu w systemie dziesiÄ™tnym.

W efekcie:

- 0.1 jest zapisywane jako liczba bardzo bliska 0.1
    
- 0.2 rÃ³wnieÅ¼
    
- ich suma daje 0.30000000000000004 zamiast dokÅ‚adnie 0.3
    

To jest **bÅ‚Ä…d reprezentacji (rounding error)**.

#### Dlaczego bezpoÅ›rednie porÃ³wnanie jest bÅ‚Ä™dne?

PorÃ³wnanie:

`suma == 0.3`

sprawdza **dokÅ‚adnÄ… rÃ³wnoÅ›Ä‡ bitowÄ…**, a nie matematycznÄ… rÃ³wnoÅ›Ä‡ w sensie â€wystarczajÄ…co bliskoâ€.

Z powodu minimalnych bÅ‚Ä™dÃ³w zaokrÄ…gleÅ„ wynik moÅ¼e siÄ™ rÃ³Å¼niÄ‡ o bardzo maÅ‚Ä… wartoÅ›Ä‡ (np. 5e-17), wiÄ™c porÃ³wnanie zwrÃ³ci `False`.

#### Poprawny sposÃ³b porÃ³wnywania

Zamiast `==` naleÅ¼y uÅ¼ywaÄ‡ porÃ³wnania z tolerancjÄ…:

`import math  math.isclose(suma, 0.3)`

lub dla NumPy:

`np.isclose(suma32, np.float32(0.3))`

MoÅ¼na teÅ¼ rÄ™cznie sprawdziÄ‡:

`abs(suma - 0.3) < 1e-9`

#### Wniosek

Suma dwÃ³ch liczb zmiennoprzecinkowych **nie zawsze** jest dokÅ‚adnie rÃ³wna wartoÅ›ci matematycznej.  
BezpoÅ›rednie porÃ³wnanie (`==`) moÅ¼e dawaÄ‡ bÅ‚Ä™dne wyniki.  
NaleÅ¼y stosowaÄ‡ porÃ³wnania z tolerancjÄ… (`isclose`).

---

## Zadanie 2
SprawdÅº, co siÄ™ stanie, gdy dodasz bardzo duÅ¼Ä… liczbÄ™ do bardzo maÅ‚ej, a nastÄ™pnie odejmiesz duÅ¼Ä… liczbÄ™ od wyniku.

```python
a = 10000000000000000  
b = 0.000000000000001  
  
wynik = (a + b) - a  
  
print(wynik)
```

```
0.0
```

#### Matematycznie

Mamy:

a = 10000000000000000  
b = 0.000000000000001

czyli:

a = 10^16  
b = 10^-15

Matematycznie:

(10^16 + 10^-15) - 10^16 = 10^-15

PowinniÅ›my dostaÄ‡:

0.000000000000001

#### Co dzieje siÄ™ w praktyce?

Wynik bÄ™dzie:

0.0

#### Dlaczego?

##### 1. Ograniczona precyzja `float64`

Liczby zmiennoprzecinkowe typu `float` w Pythonie majÄ…:

- 64 bity
    
- okoÅ‚o 15â€“16 cyfr znaczÄ…cych
    

Liczba:

10000000000000000

ma juÅ¼ **16 cyfr znaczÄ…cych**.

To oznacza, Å¼e:

- caÅ‚a dostÄ™pna precyzja jest zuÅ¼yta na zapis tej duÅ¼ej liczby,
    
- nie ma juÅ¼ miejsca na zapis bardzo maÅ‚ej zmiany rzÄ™du `10^-15`.
    

##### 2. Co dzieje siÄ™ przy dodawaniu?

Komputer prÃ³buje policzyÄ‡:

10000000000000000 + 0.000000000000001

Ale rÃ³Å¼nica rzÄ™dÃ³w wielkoÅ›ci wynosi:

10^16 vs 10^-15

To rÃ³Å¼nica **31 rzÄ™dÃ³w wielkoÅ›ci**.

MaÅ‚a liczba jest tak niewyobraÅ¼alnie maÅ‚a wzglÄ™dem duÅ¼ej, Å¼e:

> jej wpÅ‚yw mieÅ›ci siÄ™ poza zakresem precyzji mantysy

W efekcie:

a + b  â‰ˆ  a

czyli w pamiÄ™ci:

10000000000000000 + 0.000000000000001  
= 10000000000000000

##### 3. Odejmowanie

Skoro w pamiÄ™ci mamy:

(a + b) = a

to:

(a + b) - a = 0

#### Co to pokazuje?

- Bardzo maÅ‚e liczby mogÄ… caÅ‚kowicie â€zniknÄ…Ä‡â€ przy dodawaniu do bardzo duÅ¼ych.
    
- Operacje na liczbach zmiennoprzecinkowych nie sÄ… dokÅ‚adne przy duÅ¼ych rÃ³Å¼nicach skali.
    
- To przykÅ‚ad **utraty precyzji** wynikajÄ…cej z ograniczonej liczby cyfr znaczÄ…cych.
    

#### Kluczowa intuicja!

To tak, jakbyÅ› prÃ³bowaÅ‚ dodaÄ‡:

10 000 000 000 000 000,00  
+ 0,000000000000001

Przy dokÅ‚adnoÅ›ci do grosza ta zmiana po prostu nie istnieje.

---

## Zadanie 3
WyÅ›wietl liczbÄ™ zmiennoprzecinkowÄ… jako float i double z precyzjÄ… do 20 miejsc po przecinku.

```python
import numpy as np  
  
liczba = 0.1  
  
# float - pojedyncza precyzja  
liczba_f = np.float32(liczba)  
  
# double - podwÃ³jna precyzja  
liczba_d = float(liczba)  
  
print("float: ", format(liczba_f, ".20f"))  
print("double: ", format(liczba_d, ".20f"))
```

```
float:  0.10000000149011611938
double:  0.10000000000000000555
```

- `float32` ma mniejszÄ… precyzjÄ™ - szybciej pojawia siÄ™ bÅ‚Ä…d.
    
- `float64` jest dokÅ‚adniejszy, ale teÅ¼ nie przechowuje 0.1 idealnie.
    
- 20 miejsc po przecinku pokazuje rzeczywistÄ… reprezentacjÄ™ w pamiÄ™ci.

---

## Zadanie 4
Oblicz 0,3 Â· 3 + 0,1 i porÃ³wnaj wynik z jego wartoÅ›ciami zaokrÄ…glonymi do doÅ‚u i do gÃ³ry (floor i ceil).

```python
import math  
  
wynik = 0.3 * 3 + 0.1  
  
print("Wynik zwykÅ‚y: ", wynik)  
print("Wynik zaokrÄ…glony w dÃ³Å‚: ", math.floor(wynik))  
print("Wynik zaokrÄ…glony w gÃ³rÄ™: ", math.ceil(wynik))
```

```
Wynik zwykÅ‚y:  0.9999999999999999
Wynik zaokrÄ…glony w dÃ³Å‚:  0
Wynik zaokrÄ…glony w gÃ³rÄ™:  1
```

>Wynik nie jest rÃ³wny dokÅ‚adnie 1 z powodu bÅ‚Ä™du reprezentacji binarnej liczb 0.3 i 0.1 w standardzie IEEE 754.

## Zadanie 5
Oblicz rÃ³Å¼nicÄ™ miÄ™dzy 1,0000001 i 1,0000000 oraz miÄ™dzy 1,0000002 i 1,0000001. WyjaÅ›nij, dlaczego wyniki mogÄ… siÄ™ rÃ³Å¼niÄ‡ od teoretycznej rÃ³Å¼nicy.

```python
wynik1 = 1.0000001 - 1.0000000  
wynik2 = 1.0000002 - 1.0000001  
  
print("wynik1: ", wynik1)  
print("wynik2: ", wynik2)
```

```
wynik1:  1.0000000005838672e-07
wynik2:  9.999999983634211e-08
```

#### Dlaczego wyniki rÃ³Å¼niÄ… siÄ™ od teoretycznej rÃ³Å¼nicy?

Dzieje siÄ™ tak z powodu **bÅ‚Ä™dÃ³w reprezentacji liczb zmiennoprzecinkowych w systemie binarnym (IEEE 754)**.

##### Liczby nie sÄ… przechowywane dokÅ‚adnie

Liczby:

1.0000001  
1.0000002

nie majÄ… idealnej reprezentacji binarnej. W pamiÄ™ci sÄ… zapisane jako **najbliÅ¼sze moÅ¼liwe przybliÅ¼enia**.

Czyli komputer faktycznie odejmuje:

(1.0000001 + maÅ‚y_bÅ‚Ä…d1) - (1.0000000 + maÅ‚y_bÅ‚Ä…d2)

##### Odejmowanie liczb bliskich sobie

Tutaj odejmujemy liczby prawie rÃ³wne:

1.0000001 - 1.0000000

To powoduje zjawisko zwane:

##### utratÄ… cyfr znaczÄ…cych (catastrophic cancellation)

Podczas odejmowania:

- duÅ¼e wspÃ³lne cyfry siÄ™ â€kasujÄ…â€,
    
- pozostaje bardzo maÅ‚a rÃ³Å¼nica,
    
- a wzglÄ™dny wpÅ‚yw bÅ‚Ä™du zaokrÄ…glenia roÅ›nie.
    

Dlatego wyniki:

1.0000000005838672e-07  
9.999999983634211e-08

rÃ³Å¼niÄ… siÄ™ minimalnie od siebie i od idealnego `1e-7`.

#### Podsumowanie
To sÄ… liczby bardzo bliskie `1e-7`, wiÄ™c obliczenia sÄ… poprawne - rÃ³Å¼nice wynikajÄ… z reprezentacji zmiennoprzecinkowej.

Wyniki rÃ³Å¼niÄ… siÄ™ od teoretycznej wartoÅ›ci, poniewaÅ¼ liczby zmiennoprzecinkowe nie sÄ… przechowywane dokÅ‚adnie w systemie binarnym. Podczas odejmowania liczb bardzo bliskich sobie dochodzi do utraty cyfr znaczÄ…cych, co powoduje, Å¼e niewielkie bÅ‚Ä™dy reprezentacji stajÄ… siÄ™ widoczne w wyniku.

---

## Zadanie 6
Podziel liczbÄ™ 1,0 przez 0,0 i liczbÄ™ 0,0 przez 0,0. SprawdÅº, co zwrÃ³cÄ… te operacje.

```python
wynik1 = 1.0 / 0.0  
wynik2 = 0.0 / 0.0  
  
print("wynik dzielenia pierwszego: ", wynik1)  
print("wynik dzielenia drugiego: ", wynik2)
```

```
Traceback (most recent call last):
  File "zad6.py", line 1, in <module>
    wynik1 = 1.0 / 0.0
             ~~~~^~~~~
ZeroDivisionError: float division by zero
-------------------------------------------
Traceback (most recent call last):
  File "zad6.py", line 2, in <module>
    wynik2 = 0.0 / 0.0
             ~~~~^~~~~
ZeroDivisionError: float division by zero
```

Mimo Å¼e liczby zmiennoprzecinkowe sÄ… zgodne ze standardem IEEE 754, Python **celowo zgÅ‚asza wyjÄ…tek**, aby zapobiec dalszym obliczeniom na niepoprawnych wartoÅ›ciach.

W Pythonie dzielenie przez zero dla liczb zmiennoprzecinkowych powoduje zgÅ‚oszenie wyjÄ…tku `ZeroDivisionError`. Jednak zgodnie ze standardem IEEE 754 operacja 1.0 / 0.0 powinna zwrÃ³ciÄ‡ nieskoÅ„czonoÅ›Ä‡ (âˆ), a 0.0 / 0.0 wartoÅ›Ä‡ NaN (Not a Number). W bibliotekach takich jak NumPy zachowanie jest zgodne z IEEE 754 i zamiast wyjÄ…tku zwracane sÄ… wartoÅ›ci `inf` oraz `nan`.

#### Co mÃ³wi standard IEEE 754?

W czystej arytmetyce IEEE 754 (np. w NumPy):

|Operacja|Wynik|
|---|---|
|`1.0 / 0.0`|`+âˆ` (infinity)|
|`-1.0 / 0.0`|`-âˆ`|
|`0.0 / 0.0`|`NaN` (Not a Number)|

#### Jak to sprawdziÄ‡ w NumPy?

```python
import numpy as np  
  
print(np.float64(1.0) / np.float64(0.0))  
print(np.float64(0.0) / np.float64(0.0))
```

Wtedy otrzymasz:

```
inf  
nan
```

(plus ostrzeÅ¼enie RuntimeWarning zamiast wyjÄ…tku)

#### RÃ³Å¼nica

- ğŸ”¹ Python (czysty `float`) â†’ zgÅ‚asza `ZeroDivisionError`
    
- ğŸ”¹ NumPy â†’ zwraca `inf` lub `nan` zgodnie z IEEE 754

---

## Zadanie 7
Oblicz maszynowy epsilon dla typÃ³w float i double i porÃ³wnaj wyniki. WyjaÅ›nij, czym jest maszynowy epsilon i jak wpÅ‚ywa na dokÅ‚adnoÅ›Ä‡ obliczeÅ„ komputerowych.

#### Maszynowy epsilon - definicja

Maszynowy epsilon ($\varepsilon_{mach}$) to najmniejsza dodatnia liczba $\varepsilon$, taka Å¼e:

$$
1 + \varepsilon > 1
$$

w arytmetyce zmiennoprzecinkowej danego typu.

Oznacza to najmniejszÄ… wartoÅ›Ä‡, ktÃ³rÄ… komputer jest w stanie â€zauwaÅ¼yÄ‡â€ przy dodaniu do 1.  
Wyznacza on granicÄ™ precyzji reprezentacji liczb w komputerze.

#### Obliczenie maszynowego epsilon w Pythonie

Maszynowy epsilon moÅ¼na wyznaczyÄ‡ algorytmicznie, zmniejszajÄ…c wartoÅ›Ä‡ $\varepsilon$ tak dÅ‚ugo, aÅ¼ suma $1 + \varepsilon$ przestanie byÄ‡ wiÄ™ksza od 1.

```python
import numpy as np

def epsilon_float32():
    eps = np.float32(1.0)
    while np.float32(1.0) + eps / np.float32(2.0) > np.float32(1.0):
        eps = eps / np.float32(2.0)
    return eps

def epsilon_float64():
    eps = 1.0
    while 1.0 + eps / 2.0 > 1.0:
        eps = eps / 2.0
    return eps

eps32 = epsilon_float32()
eps64 = epsilon_float64()

print("Epsilon float32:", eps32)
print("Epsilon float64:", eps64)
````

```
Epsilon float32: 1.1920929e-07
Epsilon float64: 2.220446049250313e-16
```

|Typ|$\varepsilon_{mach}$|
|---|---|
|float32|â‰ˆ 1.19 Â· 10â»â·|
|float64|â‰ˆ 2.22 Â· 10â»Â¹â¶|

PorÃ³wnujÄ…c wartoÅ›ci:

$$  
\frac{1.19 \cdot 10^{-7}}{2.22 \cdot 10^{-16}} \approx 10^9  
$$

Oznacza to, Å¼e typ **float64 jest okoÅ‚o miliard razy dokÅ‚adniejszy niÅ¼ float32**.

#### WpÅ‚yw maszynowego epsilon na dokÅ‚adnoÅ›Ä‡ obliczeÅ„

##### 1. Ogranicza liczbÄ™ cyfr znaczÄ…cych

- float32 â†’ okoÅ‚o 7 cyfr znaczÄ…cych
    
- float64 â†’ okoÅ‚o 15â€“16 cyfr znaczÄ…cych
    

##### 2. OkreÅ›la maksymalny wzglÄ™dny bÅ‚Ä…d pojedynczej operacji

KaÅ¼da operacja arytmetyczna wprowadza bÅ‚Ä…d rzÄ™du $\varepsilon_{mach}$.

##### 3. WpÅ‚ywa na stabilnoÅ›Ä‡ obliczeÅ„

- Przy odejmowaniu liczb bardzo bliskich sobie moÅ¼e dojÅ›Ä‡ do utraty cyfr znaczÄ…cych.
    
- Przy duÅ¼ej liczbie operacji bÅ‚Ä™dy mogÄ… siÄ™ kumulowaÄ‡.
    

##### 4ï¸. Wyznacza granicÄ™ rozrÃ³Å¼nialnoÅ›ci liczb

JeÅ›li dodamy do 1 liczbÄ™ mniejszÄ… niÅ¼ $\varepsilon_{mach}$, wynik nadal bÄ™dzie rÃ³wny 1, poniewaÅ¼ zmiana jest poniÅ¼ej granicy precyzji.

#### Wniosek

Maszynowy epsilon:

- dla **float32** wynosi okoÅ‚o **1.19 Â· 10â»â·**
    
- dla **float64** wynosi okoÅ‚o **2.22 Â· 10â»Â¹â¶**
    

Im mniejszy epsilon, tym wiÄ™ksza dokÅ‚adnoÅ›Ä‡ obliczeÅ„ komputerowych.  
Dlatego typ double (float64) zapewnia znacznie wiÄ™kszÄ… precyzjÄ™ niÅ¼ float (float32).

---

## Zadanie 8

Sumuj liczbÄ™ 0,0001 w pÄ™tli 1.000.000 razy i porÃ³wnaj wynik z wynikiem uzyskanym przez mnoÅ¼enie 1.000.000 przez 0,0001. WyjaÅ›nij, dlaczego mogÄ… wystÄ…piÄ‡ rÃ³Å¼nice.

```python
# liczba iteracji  
n = 1_000_000  
wartosc = 0.0001  
  
# Sumowanie w pÄ™tli  
suma_petla = 0.0  
for _ in range(n):  
    suma_petla += wartosc  
  
# MnoÅ¼enie  
suma_mnozenie = n * wartosc  
  
# RÃ³Å¼nica  
roznica = suma_petla - suma_mnozenie  
  
print("Wynik sumowania w pÄ™tli:", suma_petla)  
print("Wynik mnoÅ¼enia:", suma_mnozenie)  
print("RÃ³Å¼nica:", roznica)
```

```
Wynik sumowania w pÄ™tli: 100.00000000219612
Wynik mnoÅ¼enia: 100.0
RÃ³Å¼nica: 2.1961170659778873e-09
```

#### Dlaczego wystÄ™puje rÃ³Å¼nica?

##### 1. 0.0001 nie ma dokÅ‚adnej reprezentacji binarnej

Liczba `0.0001` nie jest zapisywana idealnie w systemie binarnym â€” jest przechowywana jako przybliÅ¼enie.

##### 2ï¸. Akumulacja bÅ‚Ä™du

W pÄ™tli wykonujemy milion operacji dodawania:

suma = suma + przybliÅ¼ona_wartoÅ›Ä‡

KaÅ¼de dodanie wprowadza bardzo maÅ‚y bÅ‚Ä…d zaokrÄ…glenia.  
Po 1 000 000 iteracjach te maÅ‚e bÅ‚Ä™dy siÄ™ sumujÄ….

To zjawisko nazywamy:

> **akumulacjÄ… bÅ‚Ä™du numerycznego**

##### 3ï¸. Dlaczego mnoÅ¼enie daje dokÅ‚adniejszy wynik?

MnoÅ¼enie wykonuje:

n * wartosc

czyli jednÄ… operacjÄ™ zamiast miliona, wiÄ™c bÅ‚Ä…d pojawia siÄ™ tylko raz, a nie milion razy.

#### Wniosek

- Sumowanie wielu maÅ‚ych liczb moÅ¼e prowadziÄ‡ do akumulacji bÅ‚Ä™dÃ³w.
    
- Wynik obliczony w pÄ™tli moÅ¼e rÃ³Å¼niÄ‡ siÄ™ od wyniku mnoÅ¼enia.
    
- To pokazuje, Å¼e operacje zmiennoprzecinkowe nie sÄ… dokÅ‚adne matematycznie.
    
- Im wiÄ™cej operacji, tym wiÄ™ksze ryzyko narastania bÅ‚Ä™du.

---

## Zadanie 9
Oblicz sumÄ™ odwrotnoÅ›ci liczb od 1 do 1.000.000 w kolejnoÅ›ci rosnÄ…cej i malejÄ…cej. PorÃ³wnaj wyniki.

```python
n = 1_000_000

# 1ï¸âƒ£ Sumowanie w kolejnoÅ›ci rosnÄ…cej (od 1 do 1_000_000)
suma_rosnaco = 0.0
for i in range(1, n + 1):
    suma_rosnaco += 1.0 / i

# 2ï¸âƒ£ Sumowanie w kolejnoÅ›ci malejÄ…cej (od 1_000_000 do 1)
suma_malejaco = 0.0
for i in range(n, 0, -1):
    suma_malejaco += 1.0 / i

# RÃ³Å¼nica
roznica = suma_rosnaco - suma_malejaco

print("Suma rosnÄ…co:", suma_rosnaco)
print("Suma malejÄ…co:", suma_malejaco)
print("RÃ³Å¼nica:", roznica)
````

Matematycznie obie sumy powinny byÄ‡ identyczne:

$$  
\sum_{i=1}^{1,000,000} \frac{1}{i}  
$$

Jest to tzw. **milionowy wyraz szeregu harmonicznego**.

W praktyce otrzymujemy:

```
Suma rosnÄ…co: 14.392726722864989
Suma malejÄ…co: 14.392726722865772
RÃ³Å¼nica: -7.833733661755105e-13
```

#### Dlaczego wyniki siÄ™ rÃ³Å¼niÄ…?

##### 1ï¸. Ograniczona precyzja liczb zmiennoprzecinkowych

Liczby typu `float` majÄ… ograniczonÄ… liczbÄ™ cyfr znaczÄ…cych (okoÅ‚o 15â€“16).

##### 2ï¸. Akumulacja bÅ‚Ä™du zaokrÄ…gleÅ„

KaÅ¼de dodawanie wprowadza bardzo maÅ‚y bÅ‚Ä…d.  
PoniewaÅ¼ wykonujemy **milion operacji**, bÅ‚Ä™dy siÄ™ kumulujÄ….

##### 3. Znaczenie kolejnoÅ›ci dodawania

To kluczowe.

#### ğŸ”¹ Sumowanie rosnÄ…co (1 â†’ 1 000 000)

Na poczÄ…tku dodajemy duÅ¼e liczby (1, 1/2, 1/3...).  
Na koÅ„cu bardzo maÅ‚e liczby (np. 1/1 000 000).

MaÅ‚e skÅ‚adniki dodawane do duÅ¼ej sumy mogÄ… zostaÄ‡ czÄ™Å›ciowo â€zgubioneâ€ z powodu ograniczonej precyzji.

#### ğŸ”¹ Sumowanie malejÄ…co (1 000 000 â†’ 1)

Najpierw dodajemy bardzo maÅ‚e liczby.  
Suma jest jeszcze maÅ‚a, wiÄ™c precyzja wzglÄ™dna jest lepsza.

Dopiero pÃ³Åºniej dodawane sÄ… wiÄ™ksze skÅ‚adniki.

â¡ Ta metoda daje zwykle **dokÅ‚adniejszy wynik**.

#### Wniosek

- Matematycznie kolejnoÅ›Ä‡ sumowania nie ma znaczenia.
    
- W arytmetyce zmiennoprzecinkowej ma znaczenie.
    
- Sumowanie od najmniejszych do najwiÄ™kszych wartoÅ›ci jest numerycznie stabilniejsze.
    
- RÃ³Å¼nice wynikajÄ… z ograniczonej precyzji i akumulacji bÅ‚Ä™dÃ³w zaokrÄ…gleÅ„.
    

---

## Zadanie 10

Niech

$$
f(x) = \sqrt{x^2 + 1} - 1
$$

oraz

$$
g(x) = \frac{x^2}{\sqrt{x^2 + 1} + 1}.
$$

Åatwo zauwaÅ¼yÄ‡, Å¼e $g = f$. Oblicz i porÃ³wnaj wartoÅ›ci funkcji $g$ i $f$ dla:

$$
x = 8^{-1},\; 8^{-2},\; 8^{-3},\; \dots
$$


#### Åatwo zauwaÅ¼yÄ‡, Å¼e algebraicznie:

$$
g(x) = f(x)
$$

poniewaÅ¼:

$$
\sqrt{x^2+1} - 1
=
\frac{(\sqrt{x^2+1}-1)(\sqrt{x^2+1}+1)}{\sqrt{x^2+1}+1}
=
\frac{x^2}{\sqrt{x^2+1}+1}
$$



#### Obliczenia w Pythonie

```python
import math

def f(x):
    return math.sqrt(x**2 + 1) - 1

def g(x):
    return x**2 / (math.sqrt(x**2 + 1) + 1)

print(f"{'x':>12} {'f(x)':>20} {'g(x)':>20} {'rÃ³Å¼nica':>20}")

for k in range(1, 11):
    x = 8**(-k)
    fx = f(x)
    gx = g(x)
    print(f"{x:12.5e} {fx:20.15e} {gx:20.15e} {(fx-gx):20.15e}")
````

```
           x                 f(x)                 g(x)              rÃ³Å¼nica
 1.25000e-01 7.782218537318641e-03 7.782218537318706e-03 -6.505213034913027e-17
 1.56250e-02 1.220628628286757e-04 1.220628628287590e-04 -8.328027937404281e-17
 1.95312e-03 1.907346813823096e-06 1.907346813826566e-06 -3.469446951953614e-18
 2.44141e-04 2.980232194360610e-08 2.980232194360612e-08 -1.323488980084844e-23
 3.05176e-05 4.656612873077393e-10 4.656612871993190e-10 1.084202172485504e-19
 3.81470e-06 7.275957614183426e-12 7.275957614156956e-12 2.646977960169689e-23
 4.76837e-07 1.136868377216160e-13 1.136868377216096e-13 6.462348535570529e-27
 5.96046e-08 1.776356839400250e-15 1.776356839400249e-15 1.577721810442024e-30
 7.45058e-09 0.000000000000000e+00 2.775557561562891e-17 -2.775557561562891e-17
 9.31323e-10 0.000000000000000e+00 4.336808689942018e-19 -4.336808689942018e-19
```

#### Co siÄ™ stanie?

Dla wiÄ™kszych wartoÅ›ci x obie funkcje dadzÄ… niemal identyczne wyniki.

Jednak gdy x staje siÄ™ bardzo maÅ‚e (np. 8â»â¸, 8â»â¹, 8â»Â¹â°):

- wartoÅ›ci f(x) zaczynajÄ… traciÄ‡ dokÅ‚adnoÅ›Ä‡,
    
- g(x) pozostaje stabilne numerycznie.
    

#### Dlaczego?

Dla bardzo maÅ‚ych x:

$$  
\sqrt{x^2+1} \approx 1  
$$

W funkcji:

$$  
f(x) = \sqrt{x^2+1} - 1  
$$

odejmujemy dwie prawie rÃ³wne liczby:

$$  
1.000000000000... - 1  
$$

Powoduje to zjawisko:

> **katastrofalnej utraty cyfr znaczÄ…cych (catastrophic cancellation)**

W wyniku tracimy znacznÄ… czÄ™Å›Ä‡ dokÅ‚adnoÅ›ci.

Natomiast funkcja:

$$  
g(x) = \frac{x^2}{\sqrt{x^2+1}+1}  
$$

nie zawiera odejmowania prawie rÃ³wnych liczb, wiÄ™c jest znacznie stabilniejsza numerycznie.

#### Wniosek

- Algebraicznie: ( f(x) = g(x) )
    
- Numerycznie: dla maÅ‚ych x funkcja g(x) daje dokÅ‚adniejsze wyniki.
    
- PowÃ³d: w f(x) wystÄ™puje utrata cyfr znaczÄ…cych.
    
- Jest to klasyczny przykÅ‚ad niestabilnoÅ›ci numerycznej.
    

Dla bardzo maÅ‚ych x funkcja g(x) powinna byÄ‡ uÅ¼ywana zamiast f(x).